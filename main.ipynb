{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94fee43-5edf-48f5-b724-938e546c5ab6",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158b73d-0373-4f1c-8e0d-e722af6f0d11",
   "metadata": {},
   "source": [
    "Perhaps a more practice-based approach could be more fruitful. can use textbook & images as RAG dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae297f4f-a3ea-404e-af80-0f0e7e74c426",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7143f7-2c31-49ad-a8e7-d3122ac1c3f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (2.9.0)\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pinecone-client\n",
      "  Using cached pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (2.0.1)\n",
      "Collecting torch\n",
      "  Using cached torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Collecting loguru>=0.5.0 (from pinecone-client)\n",
      "  Using cached loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pinecone-client) (4.8.0)\n",
      "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
      "  Using cached dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pinecone-client) (2.0.7)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (4.35.0)\n",
      "Requirement already satisfied: torchvision in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (0.15.2)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting nltk (from sentence-transformers)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: sentencepiece in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (0.1.98)\n",
      "Requirement already satisfied: filelock in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m666.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:09\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m543.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch)\n",
      "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: click in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Collecting joblib (from nltk->sentence-transformers)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.2.2)\n",
      "Requirement already satisfied: wheel in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.3)\n",
      "Requirement already satisfied: cmake in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from triton==2.0.0->torch) (3.27.7)\n",
      "Requirement already satisfied: lit in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from triton==2.0.0->torch) (17.0.4)\n",
      "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.4/179.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=d0923deadf0c81b32b71c27a32f10cc6c213f666777e90582bbaec797002ec79\n",
      "  Stored in directory: /home/developer/.cache/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: threadpoolctl, scipy, loguru, joblib, dnspython, scikit-learn, pinecone-client, nltk, datasets, sentence-transformers\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.9.0\n",
      "    Uninstalling datasets-2.9.0:\n",
      "      Successfully uninstalled datasets-2.9.0\n",
      "Successfully installed datasets-2.14.6 dnspython-2.4.2 joblib-1.3.2 loguru-0.7.2 nltk-3.8.1 pinecone-client-2.2.4 scikit-learn-1.3.2 scipy-1.11.3 sentence-transformers-2.2.2 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets pinecone-client sentence-transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede1cd5-4a1e-438b-ba0a-416aa149a398",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb854ea-4700-4219-9c5c-1928ceed09ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/envs/andy/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset from huggingface in streaming mode and shuffle it\n",
    "radiology_data = load_dataset(\n",
    "    path = 'Ka4on/radiology',\n",
    "    split='train',\n",
    "    streaming=True\n",
    ").shuffle(seed=960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c948125-9ebb-4a12-bd96-0abdd6596b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Generate impression based on medical findings.',\n",
       " 'input': 'Dysarthria. There is no evidence of intracranial hemorrhage, mass, or acute infarct. There are mild scattered foci of cerebral white matter T2 hyperintensity. There is diffuse cerebral volume loss, which is most pronounced in the medial temporal lobes. There is no midline shift or herniation. The major cerebral flow voids are intact. The orbits, skull, paranasal sinuses, and scalp soft tissues are grossly unremarkable.',\n",
       " 'output': '1. Nonspecific mild scattered foci of cerebral white matter T2 hyperintensity may represent chronic small vessel ischemic disease. Otherwise, no evidence of acute infarction.2. Diffuse cerebral volume loss, which is most pronounced in the medial temporal lobes, which may represent Alzheimer disease in the appropriate clinical setting. '}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# streaming mode allows us to iterate over the dataset without needing to download it\n",
    "# show the contents of a single document in the dataset\n",
    "next(iter(radiology_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd1cabe-d3b7-4e46-a7e9-8f4c26c05d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 50000/50000 [00:04<00:00, 10365.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "total_prognosis_count = 50000\n",
    "\n",
    "counter = 0\n",
    "docs = []\n",
    "\n",
    "for d in tqdm(radiology_data, total=total_prognosis_count):\n",
    "    # extract the fields we need\n",
    "    doc = {\n",
    "        \"input\": d[\"input\"],\n",
    "        \"output\": d[\"output\"],\n",
    "    }\n",
    "    docs.append(doc)\n",
    "\n",
    "    # stop iteration once we reach 50k\n",
    "    if counter == total_prognosis_count:\n",
    "        break\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd185c5-e305-4e44-a06d-fc39d0f36732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dysarthria. There is no evidence of intracrani...</td>\n",
       "      <td>1. Nonspecific mild scattered foci of cerebral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male 8 years old Reason: Ao root dilatation Le...</td>\n",
       "      <td>1. Status post arterial switch operation.2. No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pituitary adenoma status post TSH in 11/2013: ...</td>\n",
       "      <td>Interval evolution postoperative findings rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>History of neuroblastoma of lumbar spine, rela...</td>\n",
       "      <td>1. Postoperative findings related to laminecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encephalopathy: confusion, encephalopathy. Man...</td>\n",
       "      <td>Scattered chronic infarcts and probable chroni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Dysarthria. There is no evidence of intracrani...   \n",
       "1  Male 8 years old Reason: Ao root dilatation Le...   \n",
       "2  Pituitary adenoma status post TSH in 11/2013: ...   \n",
       "3  History of neuroblastoma of lumbar spine, rela...   \n",
       "4  Encephalopathy: confusion, encephalopathy. Man...   \n",
       "\n",
       "                                              output  \n",
       "0  1. Nonspecific mild scattered foci of cerebral...  \n",
       "1  1. Status post arterial switch operation.2. No...  \n",
       "2  Interval evolution postoperative findings rela...  \n",
       "3  1. Postoperative findings related to laminecto...  \n",
       "4  Scattered chronic infarcts and probable chroni...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(docs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33584ea7-0cef-49e7-bc46-3d543db254e1",
   "metadata": {},
   "source": [
    "# Initialize Pinecone idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9ef576-bc4a-4abb-ad8e-e4174cb5158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# connect to pinecone environment\n",
    "pinecone.init(\n",
    "    api_key=\"05ce3e92-d0da-4ef4-9e3b-2a1ad822689b\",\n",
    "    environment=\"us-east1-gcp\"  # find next to API key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0457215a-b7e3-47c6-bdd1-86d798f69be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"qa\"\n",
    "\n",
    "# check if the abstractive-question-answering index exists\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # create the index if it does not exist\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "# connect to abstractive-question-answering index we created\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79ab56-e466-4bf9-b122-b8ea138d1cb6",
   "metadata": {},
   "source": [
    "# Initialize Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f819f11-cfe4-4800-a7b5-9ea8adbdcb72",
   "metadata": {},
   "source": [
    "##### Retriever Tasks:\n",
    "\n",
    "- Generate embeddings for all historical passages (context vectors/embeddings)\n",
    "- Generate embeddings for our questions (query vector/embedding)\n",
    "\n",
    "The retriever will create embeddings such that the questions and passages that hold the answers to our queries are close to one another in the vector space. \n",
    "\n",
    "Uses SentenceTransformer model based on Microsoft's MPNet as our retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c417aecc-44bf-436a-8205-00a63dc44eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/envs/andy/lib/python3.11/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)e933c/.gitattributes: 100%|█████| 737/737 [00:00<00:00, 4.39MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|█████| 190/190 [00:00<00:00, 1.26MB/s]\n",
      "Downloading (…)cbe6ee933c/README.md: 100%|█| 9.85k/9.85k [00:00<00:00, 28.8MB/s]\n",
      "Downloading (…)e6ee933c/config.json: 100%|█████| 591/591 [00:00<00:00, 3.17MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████| 116/116 [00:00<00:00, 843kB/s]\n",
      "Downloading (…)33c/data_config.json: 100%|█| 15.7k/15.7k [00:00<00:00, 77.7MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:04<00:00, 105MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|████| 53.0/53.0 [00:00<00:00, 294kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████| 239/239 [00:00<00:00, 1.32MB/s]\n",
      "Downloading (…)e933c/tokenizer.json: 100%|███| 466k/466k [00:00<00:00, 3.88MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|█████| 383/383 [00:00<00:00, 2.70MB/s]\n",
      "Downloading (…)933c/train_script.py: 100%|█| 13.2k/13.2k [00:00<00:00, 43.7MB/s]\n",
      "Downloading (…)cbe6ee933c/vocab.txt: 100%|███| 232k/232k [00:00<00:00, 3.84MB/s]\n",
      "Downloading (…)6ee933c/modules.json: 100%|█████| 349/349 [00:00<00:00, 2.12MB/s]\n",
      "/home/developer/anaconda3/envs/andy/lib/python3.11/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# set device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "retriever = SentenceTransformer(\"flax-sentence-embeddings/all_datasets_v3_mpnet-base\", device=device)\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c009ae1",
   "metadata": {},
   "source": [
    "# Generate Embeddings and Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257559a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 782/782 [30:06<00:00,  2.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 50001}},\n",
       " 'total_vector_count': 50001}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(df))\n",
    "    # extract batch\n",
    "    batch = df.iloc[i:i_end]\n",
    "    # generate embeddings for batch\n",
    "    emb = retriever.encode(batch[\"input\"].tolist()).tolist()\n",
    "    # get metadata\n",
    "    meta = batch.to_dict(orient=\"records\")\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb, meta))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5f1d7",
   "metadata": {},
   "source": [
    "# Initialize Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d32de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|████| 27.0/27.0 [00:00<00:00, 189kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|███| 899k/899k [00:00<00:00, 14.8MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 456k/456k [00:00<00:00, 22.8MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.36M/1.36M [00:00<00:00, 6.53MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█| 1.32k/1.32k [00:00<00:00, 3.41MB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████| 1.63G/1.63G [00:19<00:00, 83.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# load bart tokenizer and model from huggingface\n",
    "# TODO: can use LLM trained on textbook, but using RAG with textbooks may be more effective\n",
    "# going to write down thought process and steps later in documentation\n",
    "tokenizer = BartTokenizer.from_pretrained('vblagoje/bart_lfqa')\n",
    "generator = BartForConditionalGeneration.from_pretrained('vblagoje/bart_lfqa').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999cdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pinecone(query, top_k):\n",
    "    # generate embeddings for the query\n",
    "    xq = retriever.encode([query]).tolist()\n",
    "    # search pinecone index for context passage with the answer\n",
    "    xc = index.query(xq, top_k=top_k, include_metadata=True)\n",
    "    return xc\n",
    "\n",
    "def format_query(query, context):\n",
    "    # extract passage_text from Pinecone search result and add the <P> tag\n",
    "    context = [f\"<P> {m['metadata']['input']}\" for m in context]\n",
    "    # concatinate all context passages\n",
    "    context = \" \".join(context)\n",
    "    # contcatinate the query and context passages\n",
    "    query = f\"question: {query} context: {context}\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db0732ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': '39306',\n",
      "              'metadata': {'input': 'Evaluate disease status for clinical '\n",
      "                                    'trial. Provide 3-D measurements are all '\n",
      "                                    'reference lesions and compare prior CT. '\n",
      "                                    'Lung cancer status post 22 cycles of '\n",
      "                                    'chemotherapy. CHEST:LUNGS AND PLEURA: '\n",
      "                                    'Right upper lobe mass measures 2.3 x 1.8 '\n",
      "                                    'cm (image 30; series 4), not '\n",
      "                                    'significantly changed from previous '\n",
      "                                    'study.MEDIASTINUM AND HILA: Small '\n",
      "                                    'pericardial effusion. Stable calcified '\n",
      "                                    'right hilar and subcarinal lymph '\n",
      "                                    'nodes.CHEST WALL: No significant '\n",
      "                                    'abnormality notedABDOMEN:LIVER, BILIARY '\n",
      "                                    'TRACT: No significant abnormality '\n",
      "                                    'notedSPLEEN: No significant abnormality '\n",
      "                                    'notedPANCREAS: No significant abnormality '\n",
      "                                    'notedADRENAL GLANDS: No significant '\n",
      "                                    'abnormality notedKIDNEYS, URETERS: No '\n",
      "                                    'significant abnormality '\n",
      "                                    'notedRETROPERITONEUM, LYMPH NODES: No '\n",
      "                                    'significant abnormality noted.BOWEL, '\n",
      "                                    'MESENTERY: No significant abnormality '\n",
      "                                    'noted.BONES, SOFT TISSUES: Diffuse, '\n",
      "                                    'predominantly sclerotic bone metastases '\n",
      "                                    'are unchanged. Again noted is narrowing '\n",
      "                                    'of the spinal canal at the level of the '\n",
      "                                    'L3 vertebral body.OTHER: No significant '\n",
      "                                    'abnormality notedPELVIS:PROSTATE, SEMINAL '\n",
      "                                    'VESICLES: No significant abnormality '\n",
      "                                    'notedBLADDER: No significant abnormality '\n",
      "                                    'notedLYMPH NODES: No significant '\n",
      "                                    'abnormality notedBOWEL, MESENTERY: No '\n",
      "                                    'significant abnormality notedBONES, SOFT '\n",
      "                                    'TISSUES: Diffuse sclerotic metastases are '\n",
      "                                    'stable.OTHER: No significant abnormality '\n",
      "                                    'noted',\n",
      "                           'output': 'No significant change from previous '\n",
      "                                     'study.'},\n",
      "              'score': 0.661904454,\n",
      "              'values': []}],\n",
      " 'namespace': ''}\n",
      "question: are there any image findings that are particularly indicative of a positive or negative prognosis for patients with lung cancer? context: <P> Evaluate disease status for clinical trial. Provide 3-D measurements are all reference lesions and compare prior CT. Lung cancer status post 22 cycles of chemotherapy. CHEST:LUNGS AND PLEURA: Right upper lobe mass measures 2.3 x 1.8 cm (image 30; series 4), not significantly changed from previous study.MEDIASTINUM AND HILA: Small pericardial effusion. Stable calcified right hilar and subcarinal lymph nodes.CHEST WALL: No significant abnormality notedABDOMEN:LIVER, BILIARY TRACT: No significant abnormality notedSPLEEN: No significant abnormality notedPANCREAS: No significant abnormality notedADRENAL GLANDS: No significant abnormality notedKIDNEYS, URETERS: No significant abnormality notedRETROPERITONEUM, LYMPH NODES: No significant abnormality noted.BOWEL, MESENTERY: No significant abnormality noted.BONES, SOFT TISSUES: Diffuse, predominantly sclerotic bone metastases are unchanged. Again noted is narrowing of the spinal canal at the level of the L3 vertebral body.OTHER: No significant abnormality notedPELVIS:PROSTATE, SEMINAL VESICLES: No significant abnormality notedBLADDER: No significant abnormality notedLYMPH NODES: No significant abnormality notedBOWEL, MESENTERY: No significant abnormality notedBONES, SOFT TISSUES: Diffuse sclerotic metastases are stable.OTHER: No significant abnormality noted\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "query = \"are there any image findings that are particularly indicative of a positive or negative prognosis for patients with lung cancer?\"\n",
    "\n",
    "context = query_pinecone(query, top_k=1)\n",
    "print(context)\n",
    "\n",
    "query = format_query(query, context['matches'])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d32a8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: would insert RAG functionality here - explore how!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b84c90",
   "metadata": {},
   "source": [
    "# Testing / Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c03908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    # tokenize the query to get input_ids\n",
    "    inputs = tokenizer([query], max_length=1024, return_tensors=\"pt\").to(device)\n",
    "    # use generator to predict output ids\n",
    "    ids = generator.generate(inputs[\"input_ids\"], num_beams=2, min_length=20, max_length=40)\n",
    "    # use tokenizer to decode the output ids\n",
    "    answer = tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    return print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00449c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a couple of things to consider. The first is that there is a lot of variability in the image quality. The second is that there is a lot of variability in the image quality\n"
     ]
    }
   ],
   "source": [
    "query = \"are there any image findings that are particularly indicative of a positive or negative prognosis for patients with lung cancer?\"\n",
    "context = query_pinecone(query, top_k=5)\n",
    "query = format_query(query, context[\"matches\"])\n",
    "generate_answer(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074daf8",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45f396",
   "metadata": {},
   "source": [
    "### source / references\n",
    "- https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/search/question-answering/abstractive-question-answering.ipynb#scrollTo=6iFLxPPvx2Tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893938b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
