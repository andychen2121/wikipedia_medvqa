{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94fee43-5edf-48f5-b724-938e546c5ab6",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158b73d-0373-4f1c-8e0d-e722af6f0d11",
   "metadata": {},
   "source": [
    "Perhaps a more practice-based approach could be more fruitful. can use textbook & images as RAG dataset.\n",
    "\n",
    "  1. Initially tried creating LLM for text modality and separate vision encoder / interpreter as vision modality. Necessitated scraping of textbooks as data for LLM backbone and VQA model. still not too sure how to go about encoding images.\n",
    "  2. Ran into 2 main problems: (a) how do you generate questions (specifically about images) and (b) fine tuning. Did research on question generation models and created a preliminary dataset of questions and answers based on the textbook but still need to explore fine tuning MedFlamingo model specifically.\n",
    "  3. The textbook isn't super detailed and the scraper isn't perfect - I decided to look into other alternatives for data and QA, starting with a Huggingface dataset with real doctor notes and prognosises. Managed to create this notebook as a pure QA model, which I can use for RAG. Should use textbook data for model fine tuning and this dataset for RAG. **Explore: Evaluating accuracy, how to add image encoding, RAG + utilizing huggingface dataset for QG.**\n",
    "  4. Need to further explore fine tuning MedFlamingo specifically. To do so, need more valid (image : relevant question : answer) pairings. Should scrape more textbooks. **Resources to explore:**\n",
    "- fine tuning vid tut: https://www.youtube.com/watch?v=eC6Hd1hFvos&t=1s&ab_channel=ShawhinTalebi\n",
    "- fine tuning llama model: https://www.datacamp.com/tutorial/fine-tuning-llama-2\n",
    "- vision model (can look at face VQA as well). keep in mind how you could potentially use this in fine tuning?: https://huggingface.co/docs/transformers/model_doc/vision-encoder-decoder\n",
    "\n",
    "### TODO:\n",
    "1. ~~question generation using this notebook's dataset~~ --> does not work; notebook should be used for RAG-esque model similar to this one! (during model fine tuning process?)\n",
    "2. explore accuracy of this notebook (**using questions generated ?**)\n",
    "3. fine tuning resources\n",
    "4. look into rag and find a relevant video\n",
    "5. vision encoding\n",
    "6. finalize process + eval more textbooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae297f4f-a3ea-404e-af80-0f0e7e74c426",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e7143f7-2c31-49ad-a8e7-d3122ac1c3f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (2.14.6)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pinecone-client in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (2.2.4)\n",
      "Requirement already satisfied: sentence-transformers in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: torch in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (2.0.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.1-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (14.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pinecone-client) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pinecone-client) (4.8.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pinecone-client) (2.0.7)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (4.35.0)\n",
      "Requirement already satisfied: torchvision in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sentence-transformers) (0.1.98)\n",
      "Requirement already satisfied: filelock in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: click in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.2.2)\n",
      "Requirement already satisfied: wheel in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.3)\n",
      "Requirement already satisfied: cmake in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from triton==2.0.0->torch) (3.27.7)\n",
      "Requirement already satisfied: lit in /home/developer/anaconda3/envs/andy/lib/python3.11/site-packages (from triton==2.0.0->torch) (17.0.4)\n",
      "Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
      "Installing collected packages: pyarrow-hotfix, datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.6\n",
      "    Uninstalling datasets-2.14.6:\n",
      "      Successfully uninstalled datasets-2.14.6\n",
      "Successfully installed datasets-2.14.7 pyarrow-hotfix-0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets pinecone-client sentence-transformers torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede1cd5-4a1e-438b-ba0a-416aa149a398",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb854ea-4700-4219-9c5c-1928ceed09ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/envs/andy/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset from huggingface in streaming mode and shuffle it\n",
    "radiology_data = load_dataset(\n",
    "    path = 'Ka4on/radiology',\n",
    "    split='train',\n",
    "    streaming=True\n",
    ").shuffle(seed=960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c948125-9ebb-4a12-bd96-0abdd6596b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Generate impression based on medical findings.',\n",
       " 'input': 'Dysarthria. There is no evidence of intracranial hemorrhage, mass, or acute infarct. There are mild scattered foci of cerebral white matter T2 hyperintensity. There is diffuse cerebral volume loss, which is most pronounced in the medial temporal lobes. There is no midline shift or herniation. The major cerebral flow voids are intact. The orbits, skull, paranasal sinuses, and scalp soft tissues are grossly unremarkable.',\n",
       " 'output': '1. Nonspecific mild scattered foci of cerebral white matter T2 hyperintensity may represent chronic small vessel ischemic disease. Otherwise, no evidence of acute infarction.2. Diffuse cerebral volume loss, which is most pronounced in the medial temporal lobes, which may represent Alzheimer disease in the appropriate clinical setting. '}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# streaming mode allows us to iterate over the dataset without needing to download it\n",
    "# show the contents of a single document in the dataset\n",
    "next(iter(radiology_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd1cabe-d3b7-4e46-a7e9-8f4c26c05d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 50000/50000 [00:04<00:00, 10365.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "total_prognosis_count = 50000\n",
    "\n",
    "counter = 0\n",
    "docs = []\n",
    "\n",
    "for d in tqdm(radiology_data, total=total_prognosis_count):\n",
    "    # extract the fields we need\n",
    "    doc = {\n",
    "        \"input\": d[\"input\"],\n",
    "        \"output\": d[\"output\"],\n",
    "    }\n",
    "    docs.append(doc)\n",
    "\n",
    "    # stop iteration once we reach 50k\n",
    "    if counter == total_prognosis_count:\n",
    "        break\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd185c5-e305-4e44-a06d-fc39d0f36732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dysarthria. There is no evidence of intracrani...</td>\n",
       "      <td>1. Nonspecific mild scattered foci of cerebral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male 8 years old Reason: Ao root dilatation Le...</td>\n",
       "      <td>1. Status post arterial switch operation.2. No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pituitary adenoma status post TSH in 11/2013: ...</td>\n",
       "      <td>Interval evolution postoperative findings rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>History of neuroblastoma of lumbar spine, rela...</td>\n",
       "      <td>1. Postoperative findings related to laminecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encephalopathy: confusion, encephalopathy. Man...</td>\n",
       "      <td>Scattered chronic infarcts and probable chroni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Dysarthria. There is no evidence of intracrani...   \n",
       "1  Male 8 years old Reason: Ao root dilatation Le...   \n",
       "2  Pituitary adenoma status post TSH in 11/2013: ...   \n",
       "3  History of neuroblastoma of lumbar spine, rela...   \n",
       "4  Encephalopathy: confusion, encephalopathy. Man...   \n",
       "\n",
       "                                              output  \n",
       "0  1. Nonspecific mild scattered foci of cerebral...  \n",
       "1  1. Status post arterial switch operation.2. No...  \n",
       "2  Interval evolution postoperative findings rela...  \n",
       "3  1. Postoperative findings related to laminecto...  \n",
       "4  Scattered chronic infarcts and probable chroni...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(docs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33584ea7-0cef-49e7-bc46-3d543db254e1",
   "metadata": {},
   "source": [
    "# Initialize Pinecone idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9ef576-bc4a-4abb-ad8e-e4174cb5158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# connect to pinecone environment\n",
    "pinecone.init(\n",
    "    api_key=\"05ce3e92-d0da-4ef4-9e3b-2a1ad822689b\",\n",
    "    environment=\"us-east1-gcp\"  # find next to API key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0457215a-b7e3-47c6-bdd1-86d798f69be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"qa\"\n",
    "\n",
    "# check if the abstractive-question-answering index exists\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # create the index if it does not exist\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "# connect to abstractive-question-answering index we created\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79ab56-e466-4bf9-b122-b8ea138d1cb6",
   "metadata": {},
   "source": [
    "# Initialize Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f819f11-cfe4-4800-a7b5-9ea8adbdcb72",
   "metadata": {},
   "source": [
    "##### Retriever Tasks:\n",
    "\n",
    "- Generate embeddings for all historical passages (context vectors/embeddings)\n",
    "- Generate embeddings for our questions (query vector/embedding)\n",
    "\n",
    "The retriever will create embeddings such that the questions and passages that hold the answers to our queries are close to one another in the vector space. \n",
    "\n",
    "Uses SentenceTransformer model based on Microsoft's MPNet as our retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c417aecc-44bf-436a-8205-00a63dc44eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/envs/andy/lib/python3.11/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)e933c/.gitattributes: 100%|█████| 737/737 [00:00<00:00, 4.39MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|█████| 190/190 [00:00<00:00, 1.26MB/s]\n",
      "Downloading (…)cbe6ee933c/README.md: 100%|█| 9.85k/9.85k [00:00<00:00, 28.8MB/s]\n",
      "Downloading (…)e6ee933c/config.json: 100%|█████| 591/591 [00:00<00:00, 3.17MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████| 116/116 [00:00<00:00, 843kB/s]\n",
      "Downloading (…)33c/data_config.json: 100%|█| 15.7k/15.7k [00:00<00:00, 77.7MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:04<00:00, 105MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|████| 53.0/53.0 [00:00<00:00, 294kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████| 239/239 [00:00<00:00, 1.32MB/s]\n",
      "Downloading (…)e933c/tokenizer.json: 100%|███| 466k/466k [00:00<00:00, 3.88MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|█████| 383/383 [00:00<00:00, 2.70MB/s]\n",
      "Downloading (…)933c/train_script.py: 100%|█| 13.2k/13.2k [00:00<00:00, 43.7MB/s]\n",
      "Downloading (…)cbe6ee933c/vocab.txt: 100%|███| 232k/232k [00:00<00:00, 3.84MB/s]\n",
      "Downloading (…)6ee933c/modules.json: 100%|█████| 349/349 [00:00<00:00, 2.12MB/s]\n",
      "/home/developer/anaconda3/envs/andy/lib/python3.11/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# set device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "retriever = SentenceTransformer(\"flax-sentence-embeddings/all_datasets_v3_mpnet-base\", device=device)\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c009ae1",
   "metadata": {},
   "source": [
    "# Generate Embeddings and Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257559a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 782/782 [30:06<00:00,  2.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 50001}},\n",
       " 'total_vector_count': 50001}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(df))\n",
    "    # extract batch\n",
    "    batch = df.iloc[i:i_end]\n",
    "    # generate embeddings for batch\n",
    "    emb = retriever.encode(batch[\"input\"].tolist()).tolist()\n",
    "    # get metadata\n",
    "    meta = batch.to_dict(orient=\"records\")\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb, meta))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5f1d7",
   "metadata": {},
   "source": [
    "# Initialize Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d32de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|████| 27.0/27.0 [00:00<00:00, 189kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|███| 899k/899k [00:00<00:00, 14.8MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|███| 456k/456k [00:00<00:00, 22.8MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.36M/1.36M [00:00<00:00, 6.53MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|█| 1.32k/1.32k [00:00<00:00, 3.41MB/s]\n",
      "Downloading pytorch_model.bin: 100%|███████| 1.63G/1.63G [00:19<00:00, 83.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# load bart tokenizer and model from huggingface\n",
    "# TODO: can use LLM trained on textbook, but using RAG with textbooks may be more effective\n",
    "# going to write down thought process and steps later in documentation\n",
    "tokenizer = BartTokenizer.from_pretrained('vblagoje/bart_lfqa')\n",
    "generator = BartForConditionalGeneration.from_pretrained('vblagoje/bart_lfqa').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999cdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pinecone(query, top_k):\n",
    "    # generate embeddings for the query\n",
    "    xq = retriever.encode([query]).tolist()\n",
    "    # search pinecone index for context passage with the answer\n",
    "    xc = index.query(xq, top_k=top_k, include_metadata=True)\n",
    "    return xc\n",
    "\n",
    "def format_query(query, context):\n",
    "    # extract passage_text from Pinecone search result and add the <P> tag\n",
    "    context = [f\"<P> {m['metadata']['input']}\" for m in context]\n",
    "    # concatinate all context passages\n",
    "    context = \" \".join(context)\n",
    "    # contcatinate the query and context passages\n",
    "    query = f\"question: {query} context: {context}\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db0732ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': '39306',\n",
      "              'metadata': {'input': 'Evaluate disease status for clinical '\n",
      "                                    'trial. Provide 3-D measurements are all '\n",
      "                                    'reference lesions and compare prior CT. '\n",
      "                                    'Lung cancer status post 22 cycles of '\n",
      "                                    'chemotherapy. CHEST:LUNGS AND PLEURA: '\n",
      "                                    'Right upper lobe mass measures 2.3 x 1.8 '\n",
      "                                    'cm (image 30; series 4), not '\n",
      "                                    'significantly changed from previous '\n",
      "                                    'study.MEDIASTINUM AND HILA: Small '\n",
      "                                    'pericardial effusion. Stable calcified '\n",
      "                                    'right hilar and subcarinal lymph '\n",
      "                                    'nodes.CHEST WALL: No significant '\n",
      "                                    'abnormality notedABDOMEN:LIVER, BILIARY '\n",
      "                                    'TRACT: No significant abnormality '\n",
      "                                    'notedSPLEEN: No significant abnormality '\n",
      "                                    'notedPANCREAS: No significant abnormality '\n",
      "                                    'notedADRENAL GLANDS: No significant '\n",
      "                                    'abnormality notedKIDNEYS, URETERS: No '\n",
      "                                    'significant abnormality '\n",
      "                                    'notedRETROPERITONEUM, LYMPH NODES: No '\n",
      "                                    'significant abnormality noted.BOWEL, '\n",
      "                                    'MESENTERY: No significant abnormality '\n",
      "                                    'noted.BONES, SOFT TISSUES: Diffuse, '\n",
      "                                    'predominantly sclerotic bone metastases '\n",
      "                                    'are unchanged. Again noted is narrowing '\n",
      "                                    'of the spinal canal at the level of the '\n",
      "                                    'L3 vertebral body.OTHER: No significant '\n",
      "                                    'abnormality notedPELVIS:PROSTATE, SEMINAL '\n",
      "                                    'VESICLES: No significant abnormality '\n",
      "                                    'notedBLADDER: No significant abnormality '\n",
      "                                    'notedLYMPH NODES: No significant '\n",
      "                                    'abnormality notedBOWEL, MESENTERY: No '\n",
      "                                    'significant abnormality notedBONES, SOFT '\n",
      "                                    'TISSUES: Diffuse sclerotic metastases are '\n",
      "                                    'stable.OTHER: No significant abnormality '\n",
      "                                    'noted',\n",
      "                           'output': 'No significant change from previous '\n",
      "                                     'study.'},\n",
      "              'score': 0.661904454,\n",
      "              'values': []}],\n",
      " 'namespace': ''}\n",
      "question: are there any image findings that are particularly indicative of a positive or negative prognosis for patients with lung cancer? context: <P> Evaluate disease status for clinical trial. Provide 3-D measurements are all reference lesions and compare prior CT. Lung cancer status post 22 cycles of chemotherapy. CHEST:LUNGS AND PLEURA: Right upper lobe mass measures 2.3 x 1.8 cm (image 30; series 4), not significantly changed from previous study.MEDIASTINUM AND HILA: Small pericardial effusion. Stable calcified right hilar and subcarinal lymph nodes.CHEST WALL: No significant abnormality notedABDOMEN:LIVER, BILIARY TRACT: No significant abnormality notedSPLEEN: No significant abnormality notedPANCREAS: No significant abnormality notedADRENAL GLANDS: No significant abnormality notedKIDNEYS, URETERS: No significant abnormality notedRETROPERITONEUM, LYMPH NODES: No significant abnormality noted.BOWEL, MESENTERY: No significant abnormality noted.BONES, SOFT TISSUES: Diffuse, predominantly sclerotic bone metastases are unchanged. Again noted is narrowing of the spinal canal at the level of the L3 vertebral body.OTHER: No significant abnormality notedPELVIS:PROSTATE, SEMINAL VESICLES: No significant abnormality notedBLADDER: No significant abnormality notedLYMPH NODES: No significant abnormality notedBOWEL, MESENTERY: No significant abnormality notedBONES, SOFT TISSUES: Diffuse sclerotic metastases are stable.OTHER: No significant abnormality noted\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "query = \"are there any image findings that are particularly indicative of a positive or negative prognosis for patients with lung cancer?\"\n",
    "\n",
    "context = query_pinecone(query, top_k=1)\n",
    "print(context)\n",
    "\n",
    "query = format_query(query, context['matches'])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: would insert RAG functionality and more fine tuning here - explore how!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b84c90",
   "metadata": {},
   "source": [
    "# Testing / Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c03908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, evaluation=False):\n",
    "    \"\"\"\n",
    "    Given a query, returns relevant answer as a string. \n",
    "    If evaluation is true, also returns vector match score\n",
    "    \"\"\"\n",
    "    # establish context from pinecone query\n",
    "    context = query_pinecone(query, top_k=5)\n",
    "    query = format_query(query, context[\"matches\"])\n",
    "    score = context[\"matches\"][0][\"score\"]\n",
    "    \n",
    "    # tokenize the query to get input_ids\n",
    "    inputs = tokenizer([query], max_length=1024, return_tensors=\"pt\").to(device)\n",
    "    # use generator to predict output ids\n",
    "    ids = generator.generate(inputs[\"input_ids\"], num_beams=2, min_length=20, max_length=40)\n",
    "    # use tokenizer to decode the output ids\n",
    "    answer = tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    \n",
    "    # return type depends on evaluation status\n",
    "    if evaluation:\n",
    "        return (answer, score)\n",
    "    else:\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00449c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a couple of things to consider. The first is that there is a lot of variability in the image quality. The second is that there is a lot of variability in the image quality\n"
     ]
    }
   ],
   "source": [
    "query = \"are there any image findings that are particularly indicative of a positive or negative prognosis for patients with lung cancer?\"\n",
    "\n",
    "answer = generate_answer(query)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56403b42",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5189f1d",
   "metadata": {},
   "source": [
    "i. how similar a variety of queries are on average to vectors in our pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f426950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;pad&gt; question: What is the name of the angiog...</td>\n",
       "      <td>[STARTUP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;pad&gt; question: What is a common complication ...</td>\n",
       "      <td>Air embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;pad&gt; question: What is SVC?&lt;/s&gt;</td>\n",
       "      <td>superior vena cava (s Vc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;pad&gt; question: What is the role of interventi...</td>\n",
       "      <td>Hepatic artery aneurysmMesenteric ischemiaAcut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;pad&gt; question: What is the name of the diseas...</td>\n",
       "      <td>Atherosclerotic renal artery stenosisFibromusc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  <pad> question: What is the name of the angiog...   \n",
       "1  <pad> question: What is a common complication ...   \n",
       "2                   <pad> question: What is SVC?</s>   \n",
       "3  <pad> question: What is the role of interventi...   \n",
       "4  <pad> question: What is the name of the diseas...   \n",
       "\n",
       "                                              answer  \n",
       "0                                          [STARTUP]  \n",
       "1                                       Air embolism  \n",
       "2                          superior vena cava (s Vc)  \n",
       "3  Hepatic artery aneurysmMesenteric ischemiaAcut...  \n",
       "4  Atherosclerotic renal artery stenosisFibromusc...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset of questions generated\n",
    "qa_dataset = pd.read_csv('qa_dataset.csv')\n",
    "qa_dataset = qa_dataset.drop('Unnamed: 0', axis='columns')\n",
    "qa_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba5b29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generating responses using model\n",
    "\n",
    "generative_responses, scores = [], []\n",
    "\n",
    "for q in tqdm(qa_dataset['question']):\n",
    "    generative_response, score = generate_answer(q, evaluation=True)\n",
    "    generative_responses.append(generative_response)\n",
    "    scores.append(score)\n",
    "\n",
    "qa_dataset['generative response'] = generative_responses\n",
    "qa_dataset['vector similarity score'] = scores\n",
    "\n",
    "qa_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8aa61fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting dataset for future use\n",
    "qa_dataset.to_csv('qa_dataset_with_qg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6cdbed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average vector similarity score: 0.592321467470339\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>generative response</th>\n",
       "      <th>vector similarity score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;pad&gt; question: What is the name of the angiog...</td>\n",
       "      <td>[STARTUP]</td>\n",
       "      <td>The angiogram shows the four phases of vascula...</td>\n",
       "      <td>0.567982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;pad&gt; question: What is a common complication ...</td>\n",
       "      <td>Air embolism</td>\n",
       "      <td>The most common complication of embolization i...</td>\n",
       "      <td>0.640801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;pad&gt; question: What is SVC?&lt;/s&gt;</td>\n",
       "      <td>superior vena cava (s Vc)</td>\n",
       "      <td>SVC is a condition where the blood vessels in ...</td>\n",
       "      <td>0.502530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;pad&gt; question: What is the role of interventi...</td>\n",
       "      <td>Hepatic artery aneurysmMesenteric ischemiaAcut...</td>\n",
       "      <td>Interventional radiology is used in a variety ...</td>\n",
       "      <td>0.594041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;pad&gt; question: What is the name of the diseas...</td>\n",
       "      <td>Atherosclerotic renal artery stenosisFibromusc...</td>\n",
       "      <td>The name of the disease that causes the appear...</td>\n",
       "      <td>0.627335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  <pad> question: What is the name of the angiog...   \n",
       "1  <pad> question: What is a common complication ...   \n",
       "2                   <pad> question: What is SVC?</s>   \n",
       "3  <pad> question: What is the role of interventi...   \n",
       "4  <pad> question: What is the name of the diseas...   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                          [STARTUP]   \n",
       "1                                       Air embolism   \n",
       "2                          superior vena cava (s Vc)   \n",
       "3  Hepatic artery aneurysmMesenteric ischemiaAcut...   \n",
       "4  Atherosclerotic renal artery stenosisFibromusc...   \n",
       "\n",
       "                                 generative response  vector similarity score  \n",
       "0  The angiogram shows the four phases of vascula...                 0.567982  \n",
       "1  The most common complication of embolization i...                 0.640801  \n",
       "2  SVC is a condition where the blood vessels in ...                 0.502530  \n",
       "3  Interventional radiology is used in a variety ...                 0.594041  \n",
       "4  The name of the disease that causes the appear...                 0.627335  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating vector context similarity\n",
    "\n",
    "print(f\"average vector similarity score: {np.mean(qa_dataset['vector similarity score'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294d79b",
   "metadata": {},
   "source": [
    "ii. accuracy of responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aeeb98a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: <pad> question: What is a nonmucinous BAC?</s>\n",
      "A: A nonmucinous BAC is a BAC that is not caused by a blood clot. It is a BAC that is not caused by a blood clot. \n",
      "\n",
      "Q: <pad> question: What is the name of the disease that causes multiple intraductal papillomas?</s>\n",
      "A: It's a type of breast cancer. It's a type of breast cancer that occurs in the breast tissue. It's a type of breast cancer that occurs in the breast tissue. It's \n",
      "\n",
      "Q: <pad> question: What is the name of the condition that can cause medullary calcification?</s>\n",
      "A: Medullary calcification is a condition that can occur in a number of different ways. It can be caused by a number of things, including: 1. Cardiac blockage 2. \n",
      "\n",
      "Q: <pad> question: What two areas of the brain are referred to as CT perfusion?</s>\n",
      "A: I'm not sure what you mean by perfusion, but I'll try to answer your question. The brain is made up of a bunch of cells called neurons. Each neuron is responsible for \n",
      "\n",
      "Q: <pad> question: What is the definition of?</s>\n",
      "A: I'm not a neurologist, but I have a degree in neuropsychology. I'm not sure if this is what you're looking for, but I can give you some insight. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# manual sampling / examination of questions with their responses\n",
    "\n",
    "def examine(i):\n",
    "    assert i in range(len(qa_dataset))\n",
    "    print('Q:', qa_dataset['question'][i])\n",
    "    print('A:', qa_dataset['generative response'][i], '\\n')\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in np.random.randint(0, len(qa_dataset), 5):\n",
    "    examine(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3384ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore RLHF or outside trained reward model; \n",
    "# can also eval based off answers of our qa dataset, but I'm not sure how accurate those are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074daf8",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45f396",
   "metadata": {},
   "source": [
    "### source / references\n",
    "- https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/search/question-answering/abstractive-question-answering.ipynb#scrollTo=6iFLxPPvx2Tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893938b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
